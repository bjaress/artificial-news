x   Dockerized FastAPI app
x   GCP Cloud Run
x   pub/sub trigger
X   automatic uploading of files
X   scheduled pub/sub
X   text-to-speech
        don't use gRPC-based client, use REST API via generic request library
        X   try with curl first
        https://cloud.google.com/text-to-speech/docs/create-audio-text-command-line
        https://cloud.google.com/text-to-speech/docs/reference/rest/v1/text/synthesize
        https://cloud.google.com/docs/authentication/api-keys
        static text for now
X   better logging
    get info from Wikipedia (just headline for now)
        wikipediaapi package
            https://pypi.org/project/Wikipedia-API/
        use HTML extraction (plain text extraction elides paragraph breaks)
            news = wikipediaapi.Wikipedia(language='en',
                extract_format=wikipediaapi.ExtractFormat.HTML
                ).page("Template:In_the_news").summary
        beautiful soup
            soup = BeautifulSoup(news, 'html.parser')
            .text
        strip parenthesized expressions, as in old version
    better error handling
    not re-doing existing episodes
        track which pages an episode contains in metadata?
    async
        in parallel
            get wikipedia article list
            get voices list
            check spreaker access
        issue HTTP response 202 (or transient error)
        in background https://fastapi.tiangolo.com/tutorial/background-tasks/
            construct script from articles
                ordering of article contents
                enforce character limit
            script -> mp3
            upload
    podcast on youtube
        channel
        sprout settings

