[i] scrape wikipedia using HTML, not wiki markup
  - too many random, quirky templates
  [x] separate branch
    html-based-scraping
  [x] set up Behave
    [x] replace Dockerfile.tests
      [x] /features
    [x] requirements-integration.txt
    [x] environment.py
      https://behave.readthedocs.io/en/stable/tutorial.html#environmental-controls
      [x] url lookups
      [x] poll wiremock ready
  [i] convert one simple integration test, temporarily disable others
    [i] convert integration test
      [x] find api call
        section list
          curl 'https://en.wikipedia.org/w/api.php?action=parse&format=json&page=Frog&prop=sections&disabletoc=1'
             | jq '.parse.sections|map({index, linkAnchor})'
        section HTML
          curl 'https://en.wikipedia.org/w/api.php?action=parse&page=Frog&prop=text&format=json&section=0'
             | jq '.parse.text["*"]'
      [x] figure out processing
        exclude
          table .reference, .references, .shortdescription, .note
        extract text from
          p, blockquote, ol, ul, dl
            entire contents of tag are indivisible chunk
            can have paragraphs within chunk for e.g. list items
            filter out empties
      [ ] choose test to convert
      [ ] comment out others
      [ ] update relevant mocking
        [ ] url
        [ ] format
      [ ] update unit tests
        [ ] use beautiful soup to grab section
        [ ] html-sanitizer
        [ ] beautiful soup again to get text of paragraphs (and others)
          p blockquote ul ol dl
        [ ] remove square-bracketed citations as well as parenthesized expressions
  [ ] convert other integrations tests
    - TBD
  [ ] merge branch in
[ ] use studio voices
[ ] podcast on spotify
    [ ] spotify settings
    [ ] spreaker settings
[ ] consider sections when ordering articles
[ ] de-dupe articles
    [ ] by full reference (title and section)
[ ] iTunes
[ ] upgrade/remove libraries (Pydantic?)
[ ] upload in preview mode
    [ ] config flag (in terraform)
    [ ] flag controls uploading to spreaker in preview mode
[ ] Audible
[ ] re-assess voices
[ ] podcast on youtube
    [ ] channel
    [ ] spreaker settings
[ ] better error handling
[ ] exclude "list of" articles





import wikitextparser as wtp
import textwrap
source = textwrap.dedent(
    """
    It has a mean diameter of approximately {{convert|220|km|sp=us}} and
    contains about one percent of the mass of the [[asteroid belt]].
    """)
parsed = wtp.parse(source)
best = parsed.sections[0]
wtp.parse(best.contents).plain_text(
    replace_templates=lambda x: str(x.arguments[0].__dir__()))
